ğŸš€ Azure Data Platform Deployment â€“ Terraform Project

This project provisions a fully modular, reusable Azure data platform using Terraform with support for staging and production environments.

## ğŸš€ Azure Data Platform Deployment â€“ Terraform Project

This project provisions a fully modular, reusable **Azure data platform** using Terraform with support for **staging** and **production** environments.

---

### ğŸ“ Folder Structure

```bash
azure-data-pipeline/
â”œâ”€â”€ modules/
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â”œâ”€â”€ outputs.tf
â”‚       â”œâ”€â”€ pipeline.json
â”œâ”€â”€ envs/
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â””â”€â”€ production/
â”‚       â”œâ”€â”€ main.tf
â”‚       â””â”€â”€ terraform.tfvars
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml
â”œâ”€â”€ README.md
```

---

### âœ… Components Included

| Component                      | Status | Notes                            |
| ------------------------------ | ------ | -------------------------------- |
| Azure Resource Group           | âœ…      | Base resource group              |
| Storage Account (LRS Tier)     | âœ…      | Secure with HTTPS only           |
| Azure SQL Server + Database    | âœ…      | Admin user, basic SKU            |
| Key Vault + Secrets            | âœ…      | Integrated with ADF MSI          |
| Azure Data Factory (ADF)       | âœ…      | GitHub publishing configured     |
| Databricks Workspace           | âœ…      | Standard SKU, managed RG         |
| ADF Linked Services (SQL, DBX) | âœ…      | Includes datasets for both       |
| ADF Pipeline (JSON)            | âœ…      | Sample pipeline + trigger        |
| Integration Runtime (Auto)     | âœ…      | AutoResolve used                 |
| Virtual Network + Subnet       | âœ…      | For private endpoints            |
| Private Endpoints (ADF, SQL)   | âœ…      | With DNS zone integration        |
| Private DNS Zones (ADF)        | âœ…      | Linked to VNet                   |
| GitHub Actions CI/CD           | âœ…      | Auto-deploys from push to `main` |

---

### âš™ Prerequisites

* Terraform CLI (v1.3+)
* Azure CLI authenticated (`az login`)
* Azure subscription with necessary roles
* GitHub repository + PAT (for ADF Git publishing)

---

### ğŸ”§ Setup Instructions

1. **Clone the repo and enter an environment:**

```bash
git clone https://github.com/your-org/azure-data-pipeline.git
cd azure-data-pipeline/envs/staging
```

2. **Initialize Terraform:**

```bash
terraform init
```

3. **Plan infrastructure changes:**

```bash
terraform plan -var-file="terraform.tfvars"
```

4. **Apply infrastructure:**

```bash
terraform apply -var-file="terraform.tfvars"
```

---

### âš¡ CI/CD via GitHub Actions

Stored in `.github/workflows/deploy.yml`

* Deploys infra on each push to `main`
* Requires secrets:

  * `ARM_CLIENT_ID`
  * `ARM_CLIENT_SECRET`
  * `ARM_SUBSCRIPTION_ID`
  * `ARM_TENANT_ID`

---

### ğŸ“˜ GitHub Integration (ADF)

* Configured in `azurerm_data_factory` via `repo_configuration`
* Commits to `main` auto-trigger pipeline updates

---

### ğŸ“Š Sample ADF Pipeline

The sample pipeline copies data from Azure SQL to Databricks (Parquet on DBFS):

* Source: SQL dataset (`my_table`)
* Sink: Databricks mount (`/mnt/data/sample.parquet`)
* Trigger: Daily at midnight (can be updated)

Defined in `pipeline.json`.

---

### ğŸ” Secrets Management

* Secrets (SQL password, tokens) are stored in **Key Vault**
* ADF MSI granted **Get/List** access via `azurerm_key_vault_access_policy`

---

### ğŸ§  Databricks Integration

* `azurerm_databricks_workspace` provisioned
* Linked to ADF via `azurerm_data_factory_linked_service_azure_databricks`
* Access token from `terraform.tfvars` used for auth

---

### ğŸ“¡ Private Network + DNS

* VNet + subnet for endpoint isolation
* ADF private endpoint + DNS zone
* Supports secure access without public exposure

---

### ğŸ“¦ Multi-Environment Deployment

```bash
cd envs/staging     # For test/staging
cd envs/production  # For production

terraform apply -var-file="terraform.tfvars"
```
